{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d23819",
   "metadata": {},
   "source": [
    "Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa61f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"/mnt/data/streamworks_user_data.csv\")\n",
    "\n",
    "# Preview first few rows\n",
    "df.head()\n",
    "\n",
    "# Data types and structure\n",
    "df.info()\n",
    "\n",
    "df.describe()\n",
    "\n",
    "\n",
    "categorical_cols = [\"gender\", \"country\", \"subscription_type\",\n",
    "                    \"received_promotions\", \"referred_by_friend\", \"is_churned\"]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\nValue counts for {col}:\")\n",
    "        print(df[col].value_counts(dropna=False))\n",
    "\n",
    "\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr = df.select_dtypes(include=[\"int64\", \"float64\"]).corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap for Numeric Variables\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5655278a",
   "metadata": {},
   "source": [
    "Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a276711",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"signup_date\"] = pd.to_datetime(df[\"signup_date\"], dayfirst=True, errors=\"coerce\")\n",
    "df[\"last_active_date\"] = pd.to_datetime(df[\"last_active_date\"], dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "\n",
    "\n",
    "# tenure in days\n",
    "df[\"tenure_days\"] = (df[\"last_active_date\"] - df[\"signup_date\"]).dt.days\n",
    "\n",
    "# loyalty flag\n",
    "df[\"is_loyal\"] = (df[\"tenure_days\"] > 180).astype(int)\n",
    "\n",
    "categorical_cols = [\"gender\", \"country\", \"subscription_type\", \n",
    "                    \"received_promotions\", \"referred_by_friend\"]\n",
    "\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "\n",
    "# Drop missing target values\n",
    "df = df.dropna(subset=[\"is_churned\"])\n",
    "\n",
    "# Fill numeric missing values\n",
    "for col in df.select_dtypes(include=[\"float64\", \"int64\"]).columns:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Fill text missing values\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ae1fb6",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b2c74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# tenure_days \n",
    "df[\"tenure_days\"] = (df[\"last_active_date\"] - df[\"signup_date\"]).dt.days\n",
    "\n",
    "# loyalty flag\n",
    "df[\"is_loyal\"] = (df[\"tenure_days\"] > 180).astype(int)\n",
    "\n",
    "# ratio of watch hours to cost\n",
    "df[\"watch_per_fee_ratio\"] = df[\"average_watch_hours\"] / df[\"monthly_fee\"]\n",
    "\n",
    "# heavy mobile user flag\n",
    "df[\"heavy_mobile_user\"] = (df[\"mobile_app_usage_pct\"] > 70).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# Avoid -inf by adding 1\n",
    "df[\"log_watch_hours\"] = np.log(df[\"average_watch_hours\"] + 1)\n",
    "\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[\"watch_hours_scaled\"] = scaler.fit_transform(df[[\"average_watch_hours\"]])\n",
    "\n",
    "\n",
    "categorical_cols = [\n",
    "    \"gender\", \n",
    "    \"country\", \n",
    "    \"subscription_type\", \n",
    "    \"received_promotions\", \n",
    "    \"referred_by_friend\"\n",
    "]\n",
    "\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "\n",
    "age_bins = [0, 24, 34, 44, 54, 64, 120]\n",
    "age_labels = [\"<25\", \"25-34\", \"35-44\", \"45-54\", \"55-64\", \"65+\"]\n",
    "\n",
    "df[\"age_group\"] = pd.cut(df[\"age\"], bins=age_bins, labels=age_labels)\n",
    "\n",
    "watch_bins = [0, 10, 30, 60, 200]\n",
    "watch_labels = [\"Low\", \"Medium\", \"High\", \"Very High\"]\n",
    "\n",
    "df[\"watch_time_category\"] = pd.cut(df[\"average_watch_hours\"], bins=watch_bins, labels=watch_labels)\n",
    "\n",
    "df = pd.get_dummies(df, columns=[\"age_group\", \"watch_time_category\"], drop_first=True)\n",
    "\n",
    "\n",
    "\n",
    "df[\"low_watch_time\"] = (df[\"average_watch_hours\"] < 10).astype(int)\n",
    "\n",
    "df[\"promo_and_low_watch\"] = (\n",
    "    (df[\"received_promotions_Yes\"] == 1) & (df[\"low_watch_time\"] == 1)\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "cols_to_drop = [\"signup_date\", \"last_active_date\"]\n",
    "\n",
    "df = df.drop(columns=cols_to_drop, errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc32026",
   "metadata": {},
   "source": [
    "Statitistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409563df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "def chi_square_test(cat_col, target=\"is_churned\"):\n",
    "    contingency = pd.crosstab(df[cat_col], df[target])\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(contingency)\n",
    "    \n",
    "    print(f\"\\nChi-Square Test: {cat_col} vs {target}\")\n",
    "    print(\"Chi2 Statistic:\", chi2)\n",
    "    print(\"p-value:\", p)\n",
    "    print(\"Degrees of Freedom:\", dof)\n",
    "    print(\"\\nContingency Table:\")\n",
    "    print(contingency)\n",
    "\n",
    "# Run tests for the required categorical columns\n",
    "for col in [\"gender\", \"received_promotions\", \"referred_by_friend\"]:\n",
    "    if col in df.columns:\n",
    "        chi_square_test(col)\n",
    "\n",
    "\n",
    "churned = df[df[\"is_churned\"] == 1][\"average_watch_hours\"]\n",
    "retained = df[df[\"is_churned\"] == 0][\"average_watch_hours\"]\n",
    "\n",
    "t_stat, p_val = stats.ttest_ind(churned, retained, equal_var=False)  # Welch t-test\n",
    "\n",
    "print(\"T-test: Watch Time Difference Between Churned & Retained Users\")\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_val)\n",
    "print(\"Mean watch hours (Churned):\", churned.mean())\n",
    "print(\"Mean watch hours (Retained):\", retained.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aefc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "corr_matrix = df.select_dtypes(include=[\"int64\", \"float64\"]).corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap (Numeric Variables)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(x=\"is_churned\", y=\"average_watch_hours\", data=df)\n",
    "plt.title(\"Watch Hours by Churn Status\")\n",
    "plt.xticks([0, 1], [\"Active (0)\", \"Churned (1)\"])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.countplot(x=\"subscription_type\", hue=\"is_churned\", data=df)\n",
    "plt.title(\"Churn by Subscription Type\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.histplot(df[\"average_watch_hours\"], kde=True)\n",
    "plt.title(\"Distribution of Average Watch Hours\")\n",
    "plt.xlabel(\"Average Watch Hours\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=\"gender\", hue=\"is_churned\", data=df)\n",
    "plt.title(\"Churn Distribution by Gender\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3775f754",
   "metadata": {},
   "source": [
    "Predictive Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18edd785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "\n",
    "X = df.drop(\"is_churned\", axis=1)\n",
    "y = df[\"is_churned\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "y_prob = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix — Logistic Regression\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
    "plt.plot([0,1], [0,1], \"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve — Logistic Regression\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": X.columns,\n",
    "    \"coefficient\": log_reg.coef_[0]\n",
    "}).sort_values(by=\"coefficient\", key=abs, ascending=False)\n",
    "\n",
    "coef_df.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae74ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "target = \"average_watch_hours\"\n",
    "\n",
    "# Select features but remove the target and churn column\n",
    "features = df.drop([\"average_watch_hours\", \"is_churned\"], axis=1)\n",
    "\n",
    "X_reg = features\n",
    "y_reg = df[target]\n",
    "\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "scaler_reg = StandardScaler()\n",
    "X_train_r_scaled = scaler_reg.fit_transform(X_train_r)\n",
    "X_test_r_scaled = scaler_reg.transform(X_test_r)\n",
    "\n",
    "\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_r_scaled, y_train_r)\n",
    "\n",
    "y_pred_r = lin_reg.predict(X_test_r_scaled)\n",
    "\n",
    "\n",
    "print(\"R²:\", r2_score(y_test_r, y_pred_r))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_r, y_pred_r)))\n",
    "print(\"MAE:\", mean_absolute_error(y_test_r, y_pred_r))\n",
    "\n",
    "residuals = y_test_r - y_pred_r\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(y_pred_r, residuals, alpha=0.5)\n",
    "plt.axhline(0, linestyle=\"--\", color=\"red\")\n",
    "plt.xlabel(\"Predicted Watch Hours\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot — Linear Regression\")\n",
    "plt.show()\n",
    "\n",
    "coef_reg_df = pd.DataFrame({\n",
    "    \"feature\": X_reg.columns,\n",
    "    \"coefficient\": lin_reg.coef_\n",
    "}).sort_values(by=\"coefficient\", key=abs, ascending=False)\n",
    "\n",
    "coef_reg_df.head(15)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
